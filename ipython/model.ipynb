{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexbraun/google_drive/code/projects/sparse/python\n",
      "/Users/alexbraun/google_drive/code/projects/texture_classifier/python\n"
     ]
    }
   ],
   "source": [
    "%cd ~/google_drive/code/projects/sparse/python\n",
    "from sparse.core.sparse_dataframe import SparseDataFrame\n",
    "from sparse.utilities.utils import *\n",
    "\n",
    "%cd ~/google_drive/code/projects/texture_classifier/python\n",
    "# %cd /home/ubuntu/texture_classifier/python\n",
    "import multiprocessing\n",
    "import cPickle\n",
    "import PIL\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "from pandas.io.pytables import HDFStore\n",
    "# from plotly import plotly\n",
    "# from plotly.graph_objs import *\n",
    "\n",
    "import core.utils\n",
    "reload(core.utils)\n",
    "from core.utils import *\n",
    "\n",
    "import core.image_scanner\n",
    "reload(core.image_scanner)\n",
    "from core.image_scanner import ImageScanner\n",
    "\n",
    "import core.pipeline\n",
    "reload(core.pipeline)\n",
    "from core.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def archive(info, hdf_path, features=['r', 'g', 'b', 'h', 's', 'v', 'fft_max', 'fft_std']):\n",
    "    hdf = HDFStore(hdf_path)\n",
    "    data = get_data(info, features=features)\n",
    "    x = data.drop('y', axis=1)\n",
    "    y = data.y\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2)\n",
    "    hdf['train_x'] = DataFrame(train_x)\n",
    "    hdf['test_x'] = DataFrame(test_x)\n",
    "    hdf['train_y'] = Series(train_y)\n",
    "    hdf['test_y'] = Series(test_y)\n",
    "    hdf.close()\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "def majority_vote(y_true, y_pred):\n",
    "    d = DataFrame([y_true, y_pred]).T\n",
    "    d.columns = ['ytrue', 'yhat']\n",
    "    lut = {k:i for i, k in enumerate(wood_mask)}\n",
    "    ilut = {v:k for k, v in lut.iteritems()}\n",
    "    d.yhat = d.yhat.apply(lambda x: lut[x])\n",
    "    d = d.groupby('ytrue').agg(lambda x: x.mode()).yhat.apply(lambda x: ilut[x])\n",
    "    d = DataFrame(d)\n",
    "    print(d[d.index == d.yhat].shape[0] / float(d.shape[0]))\n",
    "    return d\n",
    "\n",
    "def predict(info, estimator):\n",
    "    y = []\n",
    "    for i, row in info.iterrows():\n",
    "        x = get_data(row.to_frame().T)\n",
    "        x = x.drop('y', axis=1)\n",
    "        x = Series(estimator.predict(x)).mode().values[0]\n",
    "        y.append(x)\n",
    "    return Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = '/Users/alexbraun/Documents/data/texture_classifier/data/texture'\n",
    "spec = [\n",
    "    'material',\n",
    "    'image_id',\n",
    "    'label',\n",
    "    'origin',\n",
    "    'desc',\n",
    "    'extension'\n",
    "]\n",
    "\n",
    "wood_mask = [\n",
    "    'olive',\n",
    "    'european-ash',\n",
    "    'african-mahogany',\n",
    "    'bamboo',\n",
    "    'sapele',\n",
    "    'kingwood',\n",
    "    'teak'\n",
    "#     'european-lime',\n",
    "#     'makore'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# random scan\n",
    "# min_res = 10\n",
    "# max_res = 100\n",
    "# PARAMS = {\n",
    "#             'scan_method':      'random_scan',\n",
    "#             'min_resolution':   (min_res, min_res),\n",
    "#             'max_resolution':   (max_res, max_res),\n",
    "#             'patches':          100,\n",
    "#             'patch_resolution': (max_res, max_res),\n",
    "# #             'normalize':        True,\n",
    "#             'bins':             256\n",
    "# #             'rotation':         'random'\n",
    "# }\n",
    "\n",
    "# grid scan\n",
    "min_res = 25\n",
    "max_res = 100\n",
    "PARAMS = {\n",
    "            'scan_method':      'grid_scan',\n",
    "            'min_resolution':   (min_res, min_res),\n",
    "            'max_resolution':   (max_res, max_res),\n",
    "            'resolutions':      4,\n",
    "            'spacing':          'even',\n",
    "#             'patch_resolution': (min_res, min_res),\n",
    "#             'normalize':        True,\n",
    "            'bins':             256\n",
    "}\n",
    "\n",
    "info = get_info(source, spec, '\\.')\n",
    "info = info[info.label.apply(lambda x: x in wood_mask)]\n",
    "\n",
    "# dataframes won't allow direct assignment of dicts\n",
    "info['params'] = None\n",
    "info.params = info.params.apply(lambda x: PARAMS)\n",
    "\n",
    "info = info[info.desc.apply(lambda x: '_d_' in x)]\n",
    "\n",
    "# info = info[info.desc.apply(lambda x: '_a_' in x)]\n",
    "info.label = info.label.apply(lambda x: re.sub('--.*', '', x))\n",
    "\n",
    "# train, test = info_split(info)\n",
    "\n",
    "# train_info = info[info.desc.apply(lambda x: '_d_' in x)]\n",
    "# test_info = info[info.origin == 'wood-database']i\n",
    "\n",
    "# train_x, test_x, train_y, test_y = archive(info, hdf_path)\n",
    "\n",
    "# info = info[info.origin != 'arroway-textures']\n",
    "# info = info.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /var/tmp/hdf_batch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%snakeviz\n",
    "\n",
    "version = '13'.zfill(3)\n",
    "hdf_path = '/Users/alexbraun/Documents/data/texture_classifier/data/hdf/data.'\n",
    "hdf_path += version + '.aw-d_wood-mask.10x10-100x100.4-even.grid.hdf'\n",
    "\n",
    "\n",
    "\n",
    "# train_x, valid_x, test_x, train_y, valid_y, test_y = archive_data(train_info, test_info, hdf_path)\n",
    "# %time train_x, test_x, train_y, test_y = archive_data(train, test, hdf_path=hdf_path, cross_val=False)\n",
    "# train_x, valid_x, test_x, train_y, valid_y, test_y = read_archive(hdf_path)\n",
    "# data = _batch_get_data(info)\n",
    "\n",
    "\n",
    "\n",
    "# data = get_data(info, hdf_path, processes=23)\n",
    "data = pd.read_hdf(hdf_path)\n",
    "X = data.drop('y', axis=1)\n",
    "y = data.y\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 50s, sys: 4.33 s, total: 10min 55s\n",
      "Wall time: 10min 55s\n",
      "{'kernel': 'linear', 'C': 1, 'max_iter': -1}\n",
      "0.180443164005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>african-mahogany</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bamboo</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>european-ash</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kingwood</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sapele</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teak</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>23603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision recall f1-score support\n",
       "0                                                 \n",
       "african-mahogany      0.16   0.09     0.12    3434\n",
       "bamboo                0.00   0.00     0.00    3258\n",
       "european-ash          0.18   0.25     0.21    3394\n",
       "kingwood              1.00   0.04     0.08    3323\n",
       "olive                 0.19   0.55     0.28    3360\n",
       "sapele                0.16   0.24     0.19    3377\n",
       "teak                  0.18   0.08     0.11    3457\n",
       "total                 0.27   0.18     0.14   23603"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "params = {\n",
    "    'C':            [1], #np.arange(0.1, 1, 0.1),\n",
    "    'kernel':       ['linear'], #, 'rbf'],\n",
    "#     'degree':       [3],\n",
    "#     'gamma':        [0.0],\n",
    "#     'coef0':        [0.0],\n",
    "#     'shrinking':    [True],\n",
    "#     'probability':  [False],\n",
    "#     'tol':          [0.001],\n",
    "#     'cache_size':   [200],\n",
    "#     'class_weight': [None],\n",
    "#     'verbose':      [False],\n",
    "    'max_iter':     [-1],\n",
    "#     'random_state': [None]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5)\n",
    "%time grid.fit(train_x, train_y)\n",
    "print(grid.best_params_)\n",
    "# pred = grid.best_estimator_.predict(valid_x)\n",
    "# valid_report = get_report(valid_y, pred)\n",
    "# valid_report\n",
    "pred = grid.best_estimator_.predict(test_x)\n",
    "print(grid.best_estimator_.score(test_x, test_y))\n",
    "report = get_report(test_y, pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 55s, sys: 1.26 s, total: 4min 56s\n",
      "Wall time: 16.3 s\n",
      "{'max_features': 38, 'n_estimators': 100, 'n_jobs': -1, 'max_depth': None}\n",
      "0.999915268599\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>african-mahogany</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bamboo</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>european-ash</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kingwood</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sapele</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teak</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision recall f1-score support\n",
       "0                                                 \n",
       "african-mahogany      1.00   1.00     1.00    1715\n",
       "bamboo                1.00   1.00     1.00    1642\n",
       "european-ash          1.00   1.00     1.00    1699\n",
       "kingwood              1.00   1.00     1.00    1655\n",
       "olive                 1.00   1.00     1.00    1686\n",
       "sapele                1.00   1.00     1.00    1685\n",
       "teak                  1.00   1.00     1.00    1720\n",
       "total                 1.00   1.00     1.00   11802"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators':        [100], #[1000],\n",
    "#     'criterion':           ['gini'],\n",
    "    'max_depth':           [None],\n",
    "#     'min_samples_split':   [2],\n",
    "#     'min_samples_leaf':    [1],\n",
    "    'max_features':        [38], \n",
    "#     'max_leaf_nodes':      [None],\n",
    "#     'bootstrap':           [True],\n",
    "#     'oob_score':           [False],\n",
    "    'n_jobs':              [-1]\n",
    "#     'random_state':        [42]\n",
    "#     'verbose':             [0],\n",
    "#     'min_density':         [None],\n",
    "#     'compute_importances': [None]\n",
    "}\n",
    "\n",
    "# train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5)\n",
    "%time grid.fit(train_x, train_y)\n",
    "print(grid.best_params_)\n",
    "# pred = grid.best_estimator_.predict(valid_x)\n",
    "# valid_report = get_report(valid_y, pred)\n",
    "# valid_report\n",
    "pred = grid.best_estimator_.predict(test_x)\n",
    "print(grid.best_estimator_.score(test_x, test_y))\n",
    "report = get_report(test_y, pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 620 ms, sys: 32.9 ms, total: 653 ms\n",
      "Wall time: 676 ms\n"
     ]
    }
   ],
   "source": [
    "def func():\n",
    "#     pkl = '/Users/alexbraun/google_drive/code/projects/texture_classifier/web/database/models/'\n",
    "    pkl = '/Users/alexbraun/Desktop/'\n",
    "    pkl += 'random-forest.arroway-d_7-woods.grid.10x10-100x100.4-even.100-est.pkl'\n",
    "    with open(pkl, 'w') as a:\n",
    "        cPickle.dump(grid.best_estimator_, a)\n",
    "    #     pickle.dump(p, a)\n",
    "    \n",
    "%time func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkl = '/Users/alexbraun/google_drive/code/projects/texture_classifier/web/database/models/random-forest.arroway-d.grid.100x100.pkl'\n",
    "p = None\n",
    "with open(pkl, 'r') as l:\n",
    "    p = cPickle.load(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model\n",
    "reload(model)\n",
    "from model import *\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "PARAMS = {\n",
    "    'scan_method':      'grid_scan',\n",
    "    'min_resolution':   (100, 100),\n",
    "    'max_resolution':   (100, 100),\n",
    "    'resolutions':      1,\n",
    "    'spacing':          'even',\n",
    "    # 'patch_resolution': (100, 100),\n",
    "    # 'normalize':        True,\n",
    "    'bins':             256\n",
    "}\n",
    "\n",
    "IMAGE_SPEC = [\n",
    "    'material',\n",
    "    'image_id',\n",
    "    'label',\n",
    "    'origin',\n",
    "    'descriptor',\n",
    "    'extension'\n",
    "]\n",
    "\n",
    "SEP = '\\.'\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# def process_data(info, features=['r', 'g', 'b', 'h', 's', 'v', 'fft_std', 'fft_max']):\n",
    "#     # create data from info\n",
    "#     data = info.copy()\n",
    "#     data.reset_index(drop=True, inplace=True)\n",
    "#     data = data[['source', 'label', 'params']]\n",
    "    \n",
    "#     err = data.source.tolist()\n",
    "\n",
    "#     data.source = data.source.apply(lambda x: PIL.Image.open(x))\n",
    "#     data = data.apply(lambda x: \n",
    "#         generate_samples(x['source'], x['label'], x['params']),\n",
    "#         axis=1\n",
    "#     )\n",
    "#     # create new expanded dataframe\n",
    "#     data = list(chain(*data.tolist()))\n",
    "#     data = DataFrame(data, columns=['x', 'y', 'params'])\n",
    "#     data['bgr'] = data.x.apply(pil_to_opencv)\n",
    "    \n",
    "#     del data['x']\n",
    "    \n",
    "#     # create feature lists\n",
    "#     rgb = filter(lambda x: x in list('rgb'), features)\n",
    "#     hsv = filter(lambda x: x in list('hsv'), features)\n",
    "#     fft = filter(lambda x: x in ['fft_std', 'fft_max'], features)\n",
    "    \n",
    "#     # rgb distributions\n",
    "#     if rgb:\n",
    "#         temp = data[['bgr', 'params']].apply(lambda x: (x['bgr'], x['params']), axis=1)\n",
    "#         for chan in rgb:\n",
    "#             chan_data = temp.apply(lambda x: get_channel_histogram(x[0], chan, **x[1]))\n",
    "#             # data[chan] = chan_data.apply(lambda x: x.tolist())\n",
    "#             create_histogram_stats(data, chan_data, chan)\n",
    "            \n",
    "#     # hsv distributions\n",
    "#     if hsv:\n",
    "#         try:\n",
    "#             data['hsv'] = data.bgr.apply(lambda x: cv2.cvtColor(x, cv2.COLOR_BGR2HSV))\n",
    "#         except:\n",
    "#             print(err)\n",
    "#             raise SyntaxError\n",
    "#         temp = data[['hsv', 'params']].apply(lambda x: (x['hsv'], x['params']), axis=1)\n",
    "#         for chan in hsv:\n",
    "#             chan_data = temp.apply(lambda x: get_channel_histogram(x[0], chan, **x[1]))\n",
    "#             # data[chan] = chan_data.apply(lambda x: x.tolist())\n",
    "#             create_histogram_stats(data, chan_data, chan)\n",
    "    \n",
    "#         del data['hsv']\n",
    "    \n",
    "#     # grain frequency\n",
    "#     if fft:\n",
    "#         data['gray'] = data.bgr.apply(lambda x: cv2.cvtColor(x, cv2.COLOR_BGR2GRAY))\n",
    "#         data.gray = data.gray.apply(lambda x: np.fft.hfft(x).astype(float))\n",
    "#         data.gray = data.gray.apply(lambda x: np.histogram(x.ravel(), bins=256)[0])\n",
    "#         if 'fft_std' in fft:\n",
    "#             data['fft_std'] = data.gray.apply(lambda x: x.std())\n",
    "#         if 'fft_max' in fft:\n",
    "#             data['fft_max'] = data.gray.apply(lambda x: x.max())\n",
    "\n",
    "#         del data['gray']\n",
    "    \n",
    "#     del data['bgr']\n",
    "#     del data['params']\n",
    "    \n",
    "#     # expand columns that contain lists\n",
    "#     # if rgb or hsv:\n",
    "#     #     data = _flatten(data)\n",
    "\n",
    "#     # shuffle data to destroy serial correlations\n",
    "#     index = data.index.tolist()\n",
    "#     np.random.shuffle(index)\n",
    "#     data = data.ix[index]\n",
    "#     data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     # Normalize features\n",
    "#     cols = data.drop('y', axis=1).columns.tolist()\n",
    "#     ss = StandardScaler()\n",
    "#     data[cols] = ss.fit_transform(data[cols])\n",
    "    \n",
    "#     return data\n",
    "\n",
    "# def create_histogram_stats(data, chan_data, channel):\n",
    "#     data[channel + '_' + 'mean']   = chan_data.apply(lambda x: x.mean() )\n",
    "#     data[channel + '_' + 'max']    = chan_data.apply(lambda x: x.max() )\n",
    "#     data[channel + '_' + 'argmax'] = chan_data.apply(lambda x: np.argmax(x) )\n",
    "#     data[channel + '_' + 'std']    = chan_data.apply(lambda x: x.std() )\n",
    "#     data[channel + '_' + 'skew']   = chan_data.apply(lambda x: scipy.stats.skew(x) )\n",
    "#     data[channel + '_' + 'kurt']   = chan_data.apply(lambda x: scipy.stats.kurtosis(x) )\n",
    "\n",
    "# class TextureClassifier(object):\n",
    "#     def __init__(self, db_path, model_name):\n",
    "#         self._db_path = db_path\n",
    "#         self._model_path = os.path.join(db_path, 'models')\n",
    "#         self._image_path = os.path.join(db_path, 'images')\n",
    "#         self._desc_path = os.path.join(db_path, 'descriptions.json')\n",
    "#         self._temp_path = os.path.join(db_path, 'temp')\n",
    "#         self.set_model(model_name)      \n",
    "    \n",
    "#     def set_model(self, model):\n",
    "#         self._model = model\n",
    "        \n",
    "#     @property\n",
    "#     def info(self):\n",
    "#         desc = None\n",
    "#         with open(self._desc_path, 'r') as d:\n",
    "#             desc = json.load(d)\n",
    "\n",
    "#         info = get_info(self._image_path, IMAGE_SPEC, sep=SEP)\n",
    "#         info['description'] = info.label.apply(\n",
    "#             lambda x: desc[x] if desc.has_key(x.lower()) else None) \n",
    "#         return info\n",
    "\n",
    "#     def get_data(self, fullpath):\n",
    "#         info = get_info(fullpath)\n",
    "#         info['label'] = 'unknown'\n",
    "#         info['params'] = None\n",
    "#         info.params = info.params.apply(lambda x: PARAMS)\n",
    "#         data = process_data(info).drop('y', axis=1)\n",
    "#         return data\n",
    "\n",
    "#     def get_results(self, pred):\n",
    "#         data = pred.merge(self.info, how='inner', on='label')\n",
    "#         data.drop_duplicates('label', inplace=True)\n",
    "#         data = data.apply(lambda x: x.to_dict(), axis=1).tolist()\n",
    "#         return data\n",
    "\n",
    "#     def predict(self, filepath):\n",
    "#         pred = self.get_data(filepath)\n",
    "#         pred = self._model.predict(pred)\n",
    "#         pred = compile_predictions(pred)\n",
    "#         pred = self.get_results(pred)\n",
    "#         return pred\n",
    "    \n",
    "db_path = '/Users/alexbraun/google_drive/code/projects/texture_classifier/web/database'\n",
    "model_name = 'random-forest.arroway-d_7-woods.grid.10x10-100x100.4-even.100-est.pkl'\n",
    "self = TextureClassifier(db_path, model_name)\n",
    "\n",
    "filepath = info.loc[1445, 'source']\n",
    "\n",
    "pred = self.get_data(filepath)\n",
    "pred = self._model.predict(pred)\n",
    "pred = compile_predictions(pred)\n",
    "pred = self.get_results(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.44140625])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_histogram_stats(data, chan_data, channel):\n",
    "    data[channel + '_' + 'mean']   = chan_data.apply(lambda x: x.mean() )\n",
    "#     data[channel + '_' + 'max']    = chan_data.apply(lambda x: x.max() )\n",
    "#     data[channel + '_' + 'argmax'] = chan_data.apply(lambda x: np.argmax(x) )\n",
    "#     data[channel + '_' + 'std']    = chan_data.apply(lambda x: x.std() )\n",
    "#     data[channel + '_' + 'skew']   = chan_data.apply(lambda x: scipy.stats.skew(x) )\n",
    "#     data[channel + '_' + 'kurt']   = chan_data.apply(lambda x: scipy.stats.kurtosis(x) )\n",
    "\n",
    "\n",
    "def process_data(info, features=['r', 'g', 'b', 'h', 's', 'v', 'fft_std', 'fft_max']):\n",
    "    # create data from info\n",
    "    data = info.copy()\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data = data[['source', 'label', 'params']]\n",
    "    \n",
    "    err = data.source.tolist()\n",
    "\n",
    "    data.source = data.source.apply(lambda x: PIL.Image.open(x))\n",
    "    data = data.apply(lambda x: \n",
    "        generate_samples(x['source'], x['label'], x['params']),\n",
    "        axis=1\n",
    "    )\n",
    "    # create new expanded dataframe\n",
    "    data = list(chain(*data.tolist()))\n",
    "    data = DataFrame(data, columns=['x', 'y', 'params'])\n",
    "    data['bgr'] = data.x.apply(pil_to_opencv)\n",
    "    \n",
    "    del data['x']\n",
    "    \n",
    "    # create feature lists\n",
    "    rgb = filter(lambda x: x in list('rgb'), features)\n",
    "    hsv = filter(lambda x: x in list('hsv'), features)\n",
    "    fft = filter(lambda x: x in ['fft_std', 'fft_max'], features)\n",
    "    \n",
    "    # rgb distributions\n",
    "    if rgb:\n",
    "        temp = data[['bgr', 'params']].apply(lambda x: (x['bgr'], x['params']), axis=1)\n",
    "        for chan in rgb:\n",
    "            chan_data = temp.apply(lambda x: get_channel_histogram(x[0], chan, **x[1]))\n",
    "            # data[chan] = chan_data.apply(lambda x: x.tolist())\n",
    "            create_histogram_stats(data, chan_data, chan)\n",
    "            \n",
    "    return data\n",
    "\n",
    "i = get_info(y)\n",
    "i['label'] = 'unknown'\n",
    "i['params'] = None\n",
    "i.params = i.params.apply(lambda x: PARAMS)\n",
    "d = process_data(i).drop('y', axis=1)\n",
    "d.r_mean.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_res = 25\n",
    "max_res = 100\n",
    "PARAMS = {\n",
    "            'scan_method':      'grid_scan',\n",
    "            'min_resolution':   (min_res, min_res),\n",
    "            'max_resolution':   (max_res, max_res),\n",
    "            'resolutions':      4,\n",
    "            'spacing':          'even',\n",
    "#             'patch_resolution': (min_res, min_res),\n",
    "#             'normalize':        True,\n",
    "            'bins':             256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
