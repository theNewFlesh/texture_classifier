{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexbraun/google_drive/code/projects/sparse/python\n",
      "/Users/alexbraun/google_drive/code/projects/texture_classifier/python\n"
     ]
    }
   ],
   "source": [
    "%cd ~/google_drive/code/projects/sparse/python\n",
    "from sparse.core.sparse_dataframe import SparseDataFrame\n",
    "from sparse.utilities.utils import *\n",
    "\n",
    "%cd ~/google_drive/code/projects/texture_classifier/python\n",
    "# %cd /home/ubuntu/texture_classifier/python\n",
    "import multiprocessing\n",
    "import PIL\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "from pandas.io.pytables import HDFStore\n",
    "# from plotly import plotly\n",
    "# from plotly.graph_objs import *\n",
    "\n",
    "import core.utils\n",
    "reload(core.utils)\n",
    "from core.utils import *\n",
    "\n",
    "import core.image_scanner\n",
    "reload(core.image_scanner)\n",
    "from core.image_scanner import ImageScanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_report(y_true, y_pred):\n",
    "    x = classification_report(y_true, y_pred)\n",
    "    x = re.sub('avg / total', 'total', x)\n",
    "    x = map(lambda x: re.split(' +', x), x.split('\\n'))\n",
    "    x = map(lambda x: filter(lambda x: x != '', x), x)\n",
    "    x = filter(lambda x: x != [], x)\n",
    "    report = DataFrame(x[1:])\n",
    "    report.set_index(0, inplace=True)\n",
    "    report.columns = x[0]\n",
    "    return report\n",
    "\n",
    "def info_split(info, test_size=0.2):\n",
    "    def _info_split(info, test_size=0.2):\n",
    "        train_x, test_x, train_y, test_y = train_test_split(info, info.common_name, test_size=test_size)\n",
    "        return DataFrame(train_x, columns=info.columns), DataFrame(test_x, columns=info.columns)\n",
    "    \n",
    "    train = []\n",
    "    test = []\n",
    "    for name in info.common_name.unique():\n",
    "        x, y = _info_split(info[info.common_name == name], test_size=test_size)\n",
    "        train.append(x)\n",
    "        test.append(y)\n",
    "    return pd.concat(train, axis=0), pd.concat(test, axis=0)\n",
    "\n",
    "def pil_to_opencv(image):\n",
    "    return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def generate_samples(image, y, params):\n",
    "    scan = ImageScanner(image, **params)\n",
    "    func = getattr(scan, params['scan_method'])\n",
    "    return [[x, y, params] for x in func(**params)]\n",
    "\n",
    "def get_data(info, features=['r', 'g', 'b', 'h', 's', 'v', 'fft_var', 'fft_max']):\n",
    "    # create data from info\n",
    "    data = info.copy()\n",
    "    data = data[['source', 'common_name', 'params']]\n",
    "    data.source = data.source.apply(lambda x: PIL.Image.open(x))\n",
    "    data = data.apply(lambda x: \n",
    "        generate_samples(x['source'], x['common_name'], x['params']),\n",
    "        axis=1\n",
    "    )\n",
    "    # create new expanded dataframe\n",
    "    data = list(chain(*data.tolist()))\n",
    "    data = DataFrame(data, columns=['x', 'y', 'params'])\n",
    "    data['bgr'] = data.x.apply(pil_to_opencv)\n",
    "    \n",
    "    del data['x']\n",
    "    \n",
    "    # create feature lists\n",
    "    rgb = filter(lambda x: x in list('rgb'), features)\n",
    "    hsv = filter(lambda x: x in list('hsv'), features)\n",
    "    fft = filter(lambda x: x in ['fft_var', 'fft_max'], features)\n",
    "    \n",
    "    # rgb distributions\n",
    "    if rgb:\n",
    "        temp = data[['bgr', 'params']].apply(lambda x: (x['bgr'], x['params']), axis=1)\n",
    "        for chan in rgb:\n",
    "            c = temp.apply(lambda x: get_channel_histogram(x[0], chan, **x[1]))\n",
    "            data[chan] = c.apply(lambda x: x.tolist())\n",
    "\n",
    "    # hsv distributions\n",
    "    if hsv:\n",
    "        data['hsv'] = data.bgr.apply(lambda x: cv2.cvtColor(x, cv2.COLOR_BGR2HSV))\n",
    "        temp = data[['hsv', 'params']].apply(lambda x: (x['hsv'], x['params']), axis=1)\n",
    "        for chan in hsv:\n",
    "            c = temp.apply(lambda x: get_channel_histogram(x[0], chan, **x[1]))\n",
    "            data[chan] = c.apply(lambda x: x.tolist())\n",
    "    \n",
    "        del data['hsv']\n",
    "    \n",
    "    # grain frequency\n",
    "    if fft:\n",
    "        data['gray'] = data.bgr.apply(lambda x: cv2.cvtColor(x, cv2.COLOR_BGR2GRAY))\n",
    "        data.gray = data.gray.apply(lambda x: np.fft.hfft(x).astype(float))\n",
    "        data.gray = data.gray.apply(lambda x: np.histogram(x.ravel(), bins=256)[0])\n",
    "        data.gray = data.gray.apply(lambda x: StandardScaler().fit_transform(x))\n",
    "        if 'fft_var' in fft:\n",
    "            data['fft_var'] = data.gray.apply(lambda x: x.var())\n",
    "        if 'fft_max' in fft:\n",
    "            data['fft_max'] = data.gray.apply(lambda x: x.max())\n",
    "\n",
    "        del data['gray']\n",
    "    \n",
    "    del data['bgr']\n",
    "    del data['params']\n",
    "    \n",
    "    # expand columns that contain lists\n",
    "    if rgb or hsv:\n",
    "        sdf = SparseDataFrame(data)\n",
    "        data = sdf.flatten(dtype=list)\n",
    "\n",
    "    # shuffle data to destroy serial correlations\n",
    "    index = data.index.tolist()\n",
    "    np.random.shuffle(index)\n",
    "    data = data.ix[index]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def _get_data(args):\n",
    "    return get_data(args[0], features=args[1])\n",
    "\n",
    "def get_data_multi(info, features=['r', 'g', 'b', 'h', 's', 'v', 'fft_var', 'fft_max'], processes=24):\n",
    "    pool = multiprocessing.Pool(processes=processes)\n",
    "    iterable = [(row.to_frame().T, features) for i, row in info.iterrows()]\n",
    "    data = pool.map(_get_data, iterable)\n",
    "    pool.close()\n",
    "    data = pd.concat(data, axis=0)\n",
    "\n",
    "    # shuffle data to destroy serial correlations\n",
    "    index = data.index.tolist()\n",
    "    np.random.shuffle(index)\n",
    "    data = data.ix[index]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = '/Users/alexbraun/Documents/data/texture_classifier/data/texture'\n",
    "spec = [\n",
    "    'material',\n",
    "    'image_id',\n",
    "    'common_name',\n",
    "    'origin',\n",
    "    'desc',\n",
    "    'extension'\n",
    "]\n",
    "\n",
    "wood_mask = [\n",
    "    'moabi',\n",
    "    'sapele',\n",
    "#     'olive-ash',\n",
    "    'european-ash',\n",
    "    'kingwood',\n",
    "    'european-lime',\n",
    "    'african-mahogany',\n",
    "    'olive'\n",
    "\n",
    "#     'macassar-ebony',\n",
    "#     'peruvian-walnut'\n",
    "#     'bog-oak',\n",
    "#     'goncalo-alves',\n",
    "#     'merbau'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random scan\n",
    "# min_res = 10\n",
    "# max_res = 100\n",
    "# params = {\n",
    "#             'scan_method':      'random_scan',\n",
    "#             'min_resolution':   (min_res, min_res),\n",
    "#             'max_resolution':   (max_res, max_res),\n",
    "#             'patches':          100,\n",
    "#             'patch_resolution': (min_res, min_res),\n",
    "#             'normalize':        True,\n",
    "#             'bins':             256\n",
    "# #             'rotation':         'random'\n",
    "# }\n",
    "\n",
    "# grid scan\n",
    "min_res = 400\n",
    "max_res = 400\n",
    "params = {\n",
    "            'scan_method':      'grid_scan',\n",
    "            'min_resolution':   (min_res, min_res),\n",
    "            'max_resolution':   (max_res, max_res),\n",
    "            'resolutions':      1,\n",
    "            'spacing':          'even',\n",
    "#             'patch_resolution': (min_res, min_res),\n",
    "            'normalize':        True,\n",
    "            'bins':             256\n",
    "}\n",
    "\n",
    "info = get_info(source, spec)\n",
    "info = info[info.common_name.apply(lambda x: x in wood_mask)]\n",
    "\n",
    "# dataframes won't allow direct assignment of dicts\n",
    "info['params'] = None\n",
    "info.params = info.params.apply(lambda x: params)\n",
    "    \n",
    "# train, test = info_split(info)\n",
    "\n",
    "train = info[info.desc.apply(lambda x: '_a_' in x)]\n",
    "test = info[info.origin != 'arroway-textures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%snakeviz\n",
    "\n",
    "def get_all_data(train, test, hdf_path=None):\n",
    "    hdf = {}\n",
    "    if hdf_path:\n",
    "        hdf = HDFStore(hdf_path)\n",
    "\n",
    "    train = get_data(train)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(train.drop('y', axis=1), train.y, test_size=0.2)\n",
    "    hdf['train_x'] = train_x\n",
    "    hdf['valid_x'] = valid_x\n",
    "    hdf['train_y'] = train_y\n",
    "    hdf['valid_y'] = valid_y\n",
    "\n",
    "    test = get_data(test)\n",
    "    test_x = test.drop('y', axis=1)\n",
    "    test_y = test.y\n",
    "\n",
    "    hdf['test_x'] = test_x\n",
    "    hdf['test_y'] = test_y\n",
    "\n",
    "    if write_hdf:\n",
    "        hdf.close()\n",
    "    \n",
    "    return train_x, valid_x, train_y, valid_y, test_x, test_y\n",
    "\n",
    "version = '1'.zfill(3)\n",
    "hdf_path = '/Users/alexbraun/Documents/data/texture_classifier/data/hdf/data'\n",
    "hdf_path += '.' + version + '.hdf'\n",
    "\n",
    "# %time\n",
    "train_x, valid_x, train_y, valid_y, test_x, test_y = get_all_data(train, test, hdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = get_data_multi(train, features=['fft_var', 'fft_max'])\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train.drop('y', axis=1), train.y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.8 s, sys: 864 ms, total: 36.7 s\n",
      "Wall time: 36.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/dev/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>african-mahogany</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>european-ash</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>european-lime</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kingwood</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moabi</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.33</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sapele</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision recall f1-score support\n",
       "0                                                 \n",
       "african-mahogany      0.15   0.10     0.12     416\n",
       "european-ash          0.07   0.06     0.07     428\n",
       "european-lime         0.00   0.00     0.00     404\n",
       "kingwood              0.00   0.00     0.00     408\n",
       "moabi                 0.00   0.00     0.00     415\n",
       "olive                 0.20   0.90     0.33     403\n",
       "sapele                0.24   0.29     0.26     414\n",
       "total                 0.09   0.19     0.11    2888"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "params = {\n",
    "    'C':            [5], #np.arange(0.1, 1, 0.1),\n",
    "    'kernel':       ['linear'],#, 'rbf'],\n",
    "#     'degree':       [3],\n",
    "#     'gamma':        [0.0],\n",
    "#     'coef0':        [0.0],\n",
    "#     'shrinking':    [True],\n",
    "#     'probability':  [False],\n",
    "#     'tol':          [0.001],\n",
    "#     'cache_size':   [200],\n",
    "#     'class_weight': [None],\n",
    "#     'verbose':      [False],\n",
    "#     'max_iter':     [1],\n",
    "#     'random_state': [None]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5)\n",
    "%time grid.fit(train_x, train_y)\n",
    "pred = grid.best_estimator_.predict(valid_x)\n",
    "valid_report = get_report(valid_y, pred)\n",
    "# pred = grid.best_estimator_.predict(test_x)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_estimator_.score(test_x, test_y))\n",
    "# report = get_report(test_y, pred)\n",
    "# report\n",
    "valid_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.142857142857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ytrue</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>african-mahogany</th>\n",
       "      <td>olive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>european-ash</th>\n",
       "      <td>olive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>european-lime</th>\n",
       "      <td>olive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kingwood</th>\n",
       "      <td>olive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moabi</th>\n",
       "      <td>olive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive</th>\n",
       "      <td>olive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sapele</th>\n",
       "      <td>european-ash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          yhat\n",
       "ytrue                         \n",
       "african-mahogany         olive\n",
       "european-ash             olive\n",
       "european-lime            olive\n",
       "kingwood                 olive\n",
       "moabi                    olive\n",
       "olive                    olive\n",
       "sapele            european-ash"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = DataFrame([valid_y, pred]).T\n",
    "d.columns = ['ytrue', 'yhat']\n",
    "lut = {k:i for i, k in enumerate(wood_mask)}\n",
    "ilut = {v:k for k, v in lut.iteritems()}\n",
    "d.yhat = d.yhat.apply(lambda x: lut[x])\n",
    "d = d.groupby('ytrue').agg(lambda x: x.mode()).yhat.apply(lambda x: ilut[x])\n",
    "d = DataFrame(d)\n",
    "print(d[d.index == d.yhat].shape[0] / float(d.shape[0]))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
