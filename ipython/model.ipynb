{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexbraun/google_drive/code/projects/sparse/python\n",
      "/Users/alexbraun/google_drive/code/projects/texture_classifier/python\n"
     ]
    }
   ],
   "source": [
    "%cd ~/google_drive/code/projects/sparse/python\n",
    "from sparse.core.sparse_dataframe import SparseDataFrame\n",
    "from sparse.utilities.utils import *\n",
    "\n",
    "%cd ~/google_drive/code/projects/texture_classifier/python\n",
    "# %cd /home/ubuntu/texture_classifier/python\n",
    "import multiprocessing\n",
    "import PIL\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "from pandas.io.pytables import HDFStore\n",
    "# from plotly import plotly\n",
    "# from plotly.graph_objs import *\n",
    "\n",
    "import core.utils\n",
    "reload(core.utils)\n",
    "from core.utils import *\n",
    "\n",
    "import core.image_scanner\n",
    "reload(core.image_scanner)\n",
    "from core.image_scanner import ImageScanner\n",
    "\n",
    "import core.pipeline\n",
    "reload(core.pipeline)\n",
    "from core.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = '/Users/alexbraun/Documents/data/texture_classifier/data/texture'\n",
    "spec = [\n",
    "    'material',\n",
    "    'image_id',\n",
    "    'common_name',\n",
    "    'origin',\n",
    "    'desc',\n",
    "    'extension'\n",
    "]\n",
    "\n",
    "wood_mask = [\n",
    "    'moabi',\n",
    "    'sapele',\n",
    "#     'olive-ash',\n",
    "    'european-ash',\n",
    "    'kingwood',\n",
    "    'european-lime',\n",
    "    'african-mahogany',\n",
    "    'olive'\n",
    "\n",
    "#     'macassar-ebony',\n",
    "#     'peruvian-walnut'\n",
    "#     'bog-oak',\n",
    "#     'goncalo-alves',\n",
    "#     'merbau'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random scan\n",
    "min_res = 10\n",
    "max_res = 100\n",
    "params = {\n",
    "            'scan_method':      'random_scan',\n",
    "            'min_resolution':   (min_res, min_res),\n",
    "            'max_resolution':   (max_res, max_res),\n",
    "            'patches':          100,\n",
    "            'patch_resolution': (min_res, min_res),\n",
    "            'normalize':        True,\n",
    "            'bins':             256\n",
    "#             'rotation':         'random'\n",
    "}\n",
    "\n",
    "# grid scan\n",
    "# min_res = 400\n",
    "# max_res = 400\n",
    "# params = {\n",
    "#             'scan_method':      'grid_scan',\n",
    "#             'min_resolution':   (min_res, min_res),\n",
    "#             'max_resolution':   (max_res, max_res),\n",
    "#             'resolutions':      1,\n",
    "#             'spacing':          'even',\n",
    "# #             'patch_resolution': (min_res, min_res),\n",
    "#             'normalize':        True,\n",
    "#             'bins':             256\n",
    "# }\n",
    "\n",
    "info = get_info(source, spec)\n",
    "info = info[info.common_name.apply(lambda x: x in wood_mask)]\n",
    "\n",
    "# dataframes won't allow direct assignment of dicts\n",
    "info['params'] = None\n",
    "info.params = info.params.apply(lambda x: params)\n",
    "    \n",
    "# train, test = info_split(info)\n",
    "\n",
    "test = info[info.desc.apply(lambda x: '_a_' in x)]\n",
    "train = info[info.origin != 'arroway-textures']\n",
    "\n",
    "# train = train.head(1)\n",
    "# test = test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%snakeviz\n",
    "\n",
    "version = '3'.zfill(3)\n",
    "hdf_path = '/Users/alexbraun/Documents/data/texture_classifier/data/hdf/data'\n",
    "hdf_path += '.' + version + '.hdf'\n",
    "\n",
    "%time train_x, valid_x, train_y, valid_y, test_x, test_y = archive_data(train, test, hdf_path)\n",
    "# archive_data(train, test, hdf_path, cross_val=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = get_data(train, features=['b', 'v'])\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train.drop('y', axis=1), train.y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "version = '2'.zfill(3)\n",
    "hdf_path = '/Users/alexbraun/Documents/data/texture_classifier/data/hdf/data'\n",
    "hdf_path += '.' + version + '.hdf'\n",
    "\n",
    "\n",
    "hdf = HDFStore(hdf_path)\n",
    "hdf['train_x'] = DataFrame(train_x)\n",
    "hdf['valid_x'] = DataFrame(valid_x)\n",
    "hdf['train_y'] = Series(train_y)\n",
    "hdf['valid_y'] = Series(valid_y)\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "params = {\n",
    "    'C':            [5], #np.arange(0.1, 1, 0.1),\n",
    "    'kernel':       ['linear'],#, 'rbf'],\n",
    "#     'degree':       [3],\n",
    "#     'gamma':        [0.0],\n",
    "#     'coef0':        [0.0],\n",
    "#     'shrinking':    [True],\n",
    "#     'probability':  [False],\n",
    "#     'tol':          [0.001],\n",
    "#     'cache_size':   [200],\n",
    "#     'class_weight': [None],\n",
    "#     'verbose':      [False],\n",
    "#     'max_iter':     [1],\n",
    "#     'random_state': [None]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5)\n",
    "%time grid.fit(train_x, train_y)\n",
    "pred = grid.best_estimator_.predict(valid_x)\n",
    "valid_report = get_report(valid_y, pred)\n",
    "# pred = grid.best_estimator_.predict(test_x)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_estimator_.score(test_x, test_y))\n",
    "# report = get_report(test_y, pred)\n",
    "# report\n",
    "valid_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = DataFrame([valid_y, pred]).T\n",
    "d.columns = ['ytrue', 'yhat']\n",
    "lut = {k:i for i, k in enumerate(wood_mask)}\n",
    "ilut = {v:k for k, v in lut.iteritems()}\n",
    "d.yhat = d.yhat.apply(lambda x: lut[x])\n",
    "d = d.groupby('ytrue').agg(lambda x: x.mode()).yhat.apply(lambda x: ilut[x])\n",
    "d = DataFrame(d)\n",
    "print(d[d.index == d.yhat].shape[0] / float(d.shape[0]))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
